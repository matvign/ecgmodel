# PyQt vs tkinter
PyQt looks nice and has a more comfortable set of widgets to program in.
It also has excellent documentation (albeit written in C++).


# Building ECG
An ECG is generated by using the equations as described in this 
[paper](http://web.mit.edu/~gari/www/papers/ieeetbe50p289.pdf).

The current implementation does not incorporate noise.


# Alpha-Beta Filter primer
The alpha-beta filter is a family of filters that attempts to produce the
actual value of a system given unreliable data.

The filter is what we're trying to model. The state is the configuration of the
system. Prediction and updating is known as system propogation. 

A prediction is known as a prior and is produced from a process error. Process 
error is some uncertainty about the system.

1. Initialize initial state
2. Predict step: predict next state using process model (w/noise)
3. Take measurement of state
4. Adjust predicted state using measurement

## Bayesian Filter
A type of alpha-beta filter that utilizes probability. Create an array of
probabilities of an event occuring. 

Given a measurement, assign probability of what state something might be in.
Proceed with next measurement and update your previous state using probability.

When adding noise to probabilities also normalize the entire array, since we 
need probability to add up to one.

## Kalman Filter
The Kalman filter is a Bayesian filter that uses gaussian distributions.

A gaussian distribution states that random samples converge on a point. 
This can be applied to random noise by using an average.

## State
The state is a list of variables for the current state of the system. 

A state for the system at k would be:
```
x_k = [position velocity]
```
where x_k contains the mean value for our gaussian distribution.


## Covariance matrix
We may have a correlation between the variables in our state. This information is captured in
what is called a covariance matrix.

The covariance matrix is in essence storing the values of our `sigma2` (variance) into a matrix.

A covariance matrix for our example above is:
```
pp pv
vp vv

where
    pp = pos pos, pv = pos vel
    vp = vel pos, vv = vel vel
```


## Prediction matrix
The kalman filter considers the k-1th state and predicts the a state for the kth.

A prediction matrix is required to move the k-1th state to the kth state.
Suppose we have a simple kinematic formula as follows:
```
p_k = p_k-1 + timechange v_k-1
v_k =         v_k-1
```

We set the values of our current state to one. So p_k-1 and v_k-1 = 1
```
1 timechange
0          1
```
This is our prediction matrix.

In addition to updating the state we also need to update our covariance matrix.
```
x_k = F_k * x_k-1
P_k = F_k * P_k-1 * F_k^T
where
    ^T indicates the identity of the matrix.
```


## External influence
External influence is added onto the state. An external influence consists of a control
matrix and a control vector.
```
x_k = F_k * x_k-1 + B_k * u_k
```


## External uncertainty
External influence is something that we already know about. External uncertainty is a force
that we don't know about.

This external uncertainty is added onto our covariance matrix.
```
P_k = F_k * P_k-1 * F_k^T + Q_k
```


## Refinement with Measurements
We can refine an estimate by providing measurements. These readings follow the same principle as the previous section. 
i.e. a state, covariance matrix and prediction matrix.

```
z_k = H_k * x_k
R_k = H_k * P_k * H_k^T
where
    H_k is the prediction matrix for the readings.
```

At this point we have two gaussian blobs, one from an estimate and another from measurements.

In order to refine our guess we should make a new guess which is combined from our estimate
and measurements.
What we end up doing is multiplying both gaussian blobs together to produce an overlap.

The rest is a bit fuzzy. We can find a kalman gain instantly or we can use some method that calculates the mean. Not sure what the correct math behind it is.

## Terminology and Symbols
x_bar: x with a bar overtop, usually either mean or prior (before measurement adjustment)


## References
The contents come from the following articles:
1. [Filter theory](https://nbviewer.jupyter.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb
)
2. [Kalman Filter Step By Step](https://towardsdatascience.com/kalman-filters-a-step-by-step-implementation-guide-in-python-91e7e123b968)
3. [How a Kalman Filter Works](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)
